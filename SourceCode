import numpy as np
import cv2 as cv
import dlib
import  sys
import  face_recognition
from PIL import Image, ImageDraw
detector = dlib.get_frontal_face_detector()
#predictor = dlib.shape_predictor(p)
cap = cv.VideoCapture(0)
if not cap.isOpened():
    print("Cannot open camera")
    exit()
while True:
    # Capture frame-by-frame
    ret, frame = cap.read()
    # if frame is read correctly ret is True
    if not ret:
        print("Can't receive frame (stream end?). Exiting ...")
        break
    # Our operations on the frame come here

    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
    rects = detector(gray, 0)
    shape = predictor(gray, rects)
    # Display the resulting frame
    cv.imshow('frame', gray)
    if cv.waitKey(1) == ord('q'):
        break
# When everything done, release the capture
cap.release()
cv.destroyAllWindows()
#img = cv.imread(cv.samples.findFile("suman.jpeg"))
#if img is None:
   # sys.exit("Could not read the image.")
#cv.imshow("Display window", img)
#k = cv.waitKey(0)
#if k == ord("s"):
    #cv.imwrite("suman.png", img)
known_image = face_recognition.load_image_file("suman.jpeg")
unknown_image = face_recognition.load_image_file("suman5.jpeg.")

#landmarks=face_recognition.face_landmarks(known_image)
#ImageDraw.Draw(landmarks,'RGBA')
suman_encoding = face_recognition.face_encodings(known_image)[0]
unknown_encoding = face_recognition.face_encodings(unknown_image)[0]
print((unknown_encoding))
results = face_recognition.compare_faces([suman_encoding], unknown_encoding)
print(results)
